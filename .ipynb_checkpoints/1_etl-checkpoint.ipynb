{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Analysis\n",
    "## ETL\n",
    "\n",
    "The aim of the following ETL was to extract the data needed to:\n",
    "\n",
    "* examine how early churn impacts the transition from 30-day trial period to becoming a paying customer\n",
    "\n",
    "* investigate what features are the most important in determining if a user will complete the first session or not.\n",
    "\n",
    "For a flow diagram of the ETL process please see 'ETL_overview.pdf'\n",
    "\n",
    "##### Table of contents:\n",
    "\n",
    "* [1. Extract user account age using session timestamps ](#first-bullet)\n",
    "* [2. Extract and clean first device and OS recorded for all users](#second-bullet)\n",
    "* [3. Merge Account length and 1st device and OS](#third-bullet)\n",
    "* [4. Filter out 2015 and 2016 accounts](#fourth-bullet)\n",
    "* [5. Extract session for first schedule for each user](#fifth-bullet)\n",
    "* [6. Extract additional useful data from database](#sixth-bullet)\n",
    "* [7. Merge all data ](#seventh-bullet)\n",
    "* [8. Save data](#eighth-bullet)\n",
    "\n",
    "Extract user account age using session timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load required functions and packages for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load helper functions for analysis\n",
    "%run x_python_scripts/ct_analysis_shared_functions.py\n",
    "\n",
    "#Device and OS data generated from sql query 'device_os_data.sql'\n",
    "device_os_data = pd.read_csv(\"x_data/device_os_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract user account age using session timestamps <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to constant_therapy database\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2012-09-16 18:47:50</td>\n",
       "      <td>2016-09-07 08:14:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2012-10-01 19:38:47</td>\n",
       "      <td>2016-12-23 19:05:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2012-10-11 13:56:07</td>\n",
       "      <td>2016-11-24 17:04:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2012-10-11 14:25:07</td>\n",
       "      <td>2016-06-20 20:02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2013-02-03 21:02:34</td>\n",
       "      <td>2016-01-01 17:07:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id          start_date            end_date\n",
       "0          10 2012-09-16 18:47:50 2016-09-07 08:14:51\n",
       "1          12 2012-10-01 19:38:47 2016-12-23 19:05:36\n",
       "2          13 2012-10-11 13:56:07 2016-11-24 17:04:36\n",
       "3          14 2012-10-11 14:25:07 2016-06-20 20:02:06\n",
       "4          15 2013-02-03 21:02:34 2016-01-01 17:07:48"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SQL query that extracts the first and last session timestamp for each patient\n",
    "# it removes the special case where completed tasks and total task are both 0 \n",
    "#(an engineering anomaly)\n",
    "account_lengths_time =''' SELECT \n",
    "s.patient_id, \n",
    "min(s.start_time) AS session_first_day,\n",
    "max(s.start_time) AS session_last_day\n",
    "\n",
    "FROM  \n",
    "constant_therapy.sessions as s\n",
    "\n",
    "WHERE\n",
    "s.task_type_id is not null -- removes parent sessions\n",
    "\n",
    "GROUP BY patient_id'''\n",
    "\n",
    "acc_len_time = run_sql(account_lengths_time)\n",
    "\n",
    "#Add column names\n",
    "acc_len_time.columns=['patient_id','start_date', 'end_date']\n",
    "\n",
    "#print(len(account_lengths_df))\n",
    "acc_len_time.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract and clean first device and OS recorded for all users <a class=\"anchor\" id=\"second-bullet\"></a>\n",
    "\n",
    "The data was pulled from the database using the sql query 'device_os_data.sql' This included filters for:\n",
    "\n",
    "   * customers.leadsource != [Clinican_Setup, HLTH, CASE]\n",
    "   * users.is_demo != 1\n",
    "   * usage_stats_by_day.sessiontype ==SCHEDULED\n",
    "\n",
    "The patients in the dataframe acc_len_time have not been filtered, but since the device_os_data has been filtered the join below imposes the filtering on acc_len_time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove duplicate entries\n",
    "Note that duplicates are due to joining on the sessions table so one row is output for each session row. Simply removing the duplicates solves the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of device_type list (lots of duplicates):\n",
      "1336717\n",
      "\n",
      "length of device_type list (NO duplicates):\n",
      "13647\n"
     ]
    }
   ],
   "source": [
    "#remove the duplicate records generated due to multiple enteries in sessions table\n",
    "device_os_data_no_duplicates = device_os_data.drop_duplicates()\n",
    "\n",
    "print(\"length of device_type list (lots of duplicates):\")\n",
    "print(len(device_os_data))\n",
    "print\n",
    "print(\"length of device_type list (NO duplicates):\")\n",
    "print(len(device_os_data_no_duplicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove users that have device_type and/or os_type as NULL\n",
    "Some devices may not have been catalogued so these training sets were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users removed: 114\n"
     ]
    }
   ],
   "source": [
    "#Select the rows in dataframe where os_type and device form are both not null\n",
    "selected = device_os_data_no_duplicates['os_type'].notnull(\n",
    "            ) & device_os_data_no_duplicates['device_form'].notnull()\n",
    "\n",
    "#Apply the filter\n",
    "device_data_clean = device_os_data_no_duplicates[selected]\n",
    "\n",
    "#Show result of filter\n",
    "users_removed = selected.value_counts()[False]\n",
    "print(\"users removed: {}\".format(users_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merge Account length and 1st device and OS <a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge device_os_data and account length dataframes\n",
    "account_data_time = device_data_clean.merge(\n",
    "    acc_len_time, left_on = 'user_id' , right_on = 'patient_id')\n",
    "\n",
    "#subset for columns we want to keep\n",
    "account_data_time = account_data_time[[\n",
    "        'user_id','os_type','device_form','start_date',\n",
    "        'end_date']] \n",
    "#,'account_age','first_month_churn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Filter out 2015 and 2016 accounts <a class=\"anchor\" id=\"fourth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keep only accounts that started and ended between 2015 and 2016\n",
    "#Accounts before this were is beta and accounts after this are still trial accounts\n",
    "account_data_time_2015_2016 = account_data_time[\n",
    "    (account_data_time['start_date'] > '2015-01-01 00:00:00') & \n",
    "    (account_data_time['start_date'] < '2017-01-01 00:00:00')  \n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Extract session for first schedule for each user  <a class=\"anchor\" id=\"fifth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to constant_therapy database\n"
     ]
    }
   ],
   "source": [
    "#Make list of users we are interested in\n",
    "#i.e. filtered for: lead_source, demo, session_type, 2015-2016, \n",
    "# completed tasks !=0 and total_task_count >0\n",
    "users_of_interest = list(account_data_time_2015_2016.user_id)\n",
    "\n",
    "#Query that take the list of users we are interested in \n",
    "# and extracts the sessions in the first schedule for each user\n",
    "query1='''create temporary table tmp \n",
    "select s.* from constant_therapy.sessions s \n",
    "join (select patient_id, id as first_sch from constant_therapy.schedules where patient_id in ('''+ ','.join(map(str, users_of_interest)) +''') group by patient_id) sch \n",
    "on sch.first_sch = s.schedule_id\n",
    "where s.task_type_id is not null\n",
    "group by s.patient_id, s.task_type_id, s.task_level\n",
    "; '''\n",
    "\n",
    "#Query that selects the columns of interest\n",
    "query2 = '''select patient_id, schedule_id, id AS session_id, task_type_id, task_level, completed_task_count , total_task_count, accuracy, latency, date(start_time) from tmp order by patient_id desc, id asc;'''\n",
    "\n",
    "#Create a connection to database\n",
    "cnx=connectmysql('constant_therapy') \n",
    "\n",
    "#create a cursor object\n",
    "cur = cnx.cursor()\n",
    "\n",
    "#execute the sql command\n",
    "cur.execute(query1)\n",
    "cur.execute(query2)\n",
    "\n",
    "#Pull the data in the cursor into a list of tuples\n",
    "first_schedules =cur.fetchall()\n",
    "\n",
    "#Pull the list of tuples into a dataframe\n",
    "first_schedules_df = pd.DataFrame(first_schedules)\n",
    "\n",
    "#Add column names\n",
    "first_schedules_df.columns=['patient_id', 'schedule_id','session_id','task_type_id', \n",
    "                            'task_level', 'completed_task_count', 'total_task_count', \n",
    "                            'accuracy','latency', 'date(start_time)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep first session data only and label users by first session completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pull out first session for each patient\n",
    "first_record = first_schedules_df.sort_values(\n",
    "    by =['patient_id','session_id'],ascending=True).groupby(\n",
    "    'patient_id').head(1).reset_index(drop=True)\n",
    "\n",
    "# Label first session completers and non-completers\n",
    "# 1 = completed first session\n",
    "# 0 = didn't complete the first session\n",
    "first_record['session_completed'] = np.where(\n",
    "    first_record['completed_task_count'] == first_record['total_task_count'], 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Extract additional useful data from database <a class=\"anchor\" id=\"sixth-bullet\"></a>\n",
    "Customer sign-up data, task_type names customer deficit information, and customer disorder information were extracted from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to ct_customer database\n",
      "Connected to constant_therapy database\n"
     ]
    }
   ],
   "source": [
    "#Extract the customer table from the database\n",
    "customer_info =  table_returner('ct_customer','customers')\n",
    "\n",
    "#Load the task_types table from database\n",
    "task_types_table =  table_returner('constant_therapy','task_types')\n",
    "\n",
    "#extract the task name and their associated ids\n",
    "task_types= task_types_table[['id','system_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract deficit features\n",
    "\n",
    "Because a customer can have multiple deficits and the original table is flattened (i.e. multiple rows for each customer), it was unflatten so that the data could be joined later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to ct_customer database\n",
      "Connected to ct_customer database\n"
     ]
    }
   ],
   "source": [
    "#Pull out the customer deficits from the database\n",
    "cust_deficit =  table_returner('ct_customer','customers_to_deficits')\n",
    "\n",
    "#Subset and unflatten the dataframe\n",
    "subset = cust_deficit[['customer_id','deficit_id']]\n",
    "customer_deficits=pd.crosstab(subset['customer_id'], subset['deficit_id'])\n",
    "\n",
    "#Give the columns better names\n",
    "#Pull out the deficit description\n",
    "deficits =  table_returner('ct_customer','deficits')\n",
    "deficit_descriptions = list(deficits['description'])\n",
    "\n",
    "new_column_names=[]\n",
    "for x in deficit_descriptions: \n",
    "    new_column_names.append('deficit: '+ x)\n",
    "\n",
    "#Add the deficit name that is missing\n",
    "new_column_names.append('deficits: 999')\n",
    "\n",
    "#switch position of column names so it matches dataframe column order\n",
    "new_column_names[9],new_column_names[8] = new_column_names[8],new_column_names[9]\n",
    "\n",
    "#rename columns in dataframe for clarity\n",
    "customer_deficits.columns=new_column_names\n",
    "customer_deficits.head()\n",
    "\n",
    "#reindex the dataframe\n",
    "customer_deficits_reindexed = customer_deficits.reset_index(\n",
    "    level=None, drop=False, inplace=False, col_level=0, col_fill='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Disorder features\n",
    "Because a customer can have multiple cognitive deficits and the original table is 'flattened', it needed to be 'unflatten' by pivoting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to ct_customer database\n",
      "Connected to ct_customer database\n"
     ]
    }
   ],
   "source": [
    "#Pull out the customer deficits from the database\n",
    "cust_disorder =  table_returner('ct_customer','customers_to_disorders')\n",
    "\n",
    "#Subset and unflatten the dataframe\n",
    "subset = cust_disorder[['customer_id','disorder_id']]\n",
    "cust_disorders=pd.crosstab(subset['customer_id'], subset['disorder_id'])\n",
    "\n",
    "#Give the columns better names\n",
    "disorders =  table_returner('ct_customer','disorders')\n",
    "#Pull out the disorder descriptions\n",
    "disorder_descriptions = list(disorders['description'])\n",
    "\n",
    "new_col_names=[]\n",
    "for x in disorder_descriptions: \n",
    "    new_col_names.append('disorder: '+ x)\n",
    "\n",
    "#rename columns in the data frame\n",
    "cust_disorders.columns=new_col_names\n",
    "cust_disorders.head()\n",
    "\n",
    "#reindex the dataframe\n",
    "cust_disorders_reindexed = cust_disorders.reset_index(\n",
    "    level=None, drop=False, inplace=False, col_level=0, col_fill='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Merge all data <a class=\"anchor\" id=\"seventh-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge account length with first session completed labelled data\n",
    "first_session = account_data_time_2015_2016.merge(\n",
    "    first_record, left_on = 'user_id' , right_on = 'patient_id')\n",
    "\n",
    "# Merge the customers with deficits and disorders data\n",
    "# Throw out any customers missing at least one entry for disorder and deficit\n",
    "# Total dropped = 18 users\n",
    "deficits_disorders = cust_disorders_reindexed.merge(\n",
    "    customer_deficits_reindexed,\n",
    "    left_on ='customer_id', \n",
    "    right_on ='customer_id',\n",
    "    how='inner')\n",
    "\n",
    "# Merge the first session customers with deficits_disorders data\n",
    "# Throw out any customers missing first session and deficit_disorder data\n",
    "# Total dropped from first session = 2712\n",
    "# This is alot! To look into: why are so many users that signed up missing first session data?\n",
    "first_session_deficits_disorders = first_session.merge(\n",
    "    deficits_disorders,\n",
    "    left_on ='user_id', \n",
    "    right_on ='customer_id',\n",
    "    how='inner')\n",
    "\n",
    "#Merge with task type to get a name instead of just a number for task_types\n",
    "first_session_deficits_disorders_tasks = first_session_deficits_disorders.merge(\n",
    "    task_types,\n",
    "    left_on ='task_type_id', \n",
    "    right_on ='id',\n",
    "    how='inner')\n",
    "\n",
    "#Merge with customer info from signup page\n",
    "first_session_deficits_disorders_tasks_customers = first_session_deficits_disorders_tasks.merge(\n",
    "    customer_info,\n",
    "    left_on ='customer_id', \n",
    "    right_on ='user_id',\n",
    "    how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality control check for merges\n",
    "The merges are working correctly as can bee seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers with disorders data\n",
      "73698\n",
      "73698\n",
      "customers with deficits data\n",
      "73709\n",
      "73709\n",
      "customers with both deficit and disorder data\n",
      "73691\n",
      "73691\n",
      "customers with first session data for 2015 and 2016\n",
      "13027\n",
      "13027\n",
      "customers with both deficit,disorder, and first session data\n",
      "10315\n",
      "10315\n",
      "customers with both deficit,disorder,task and first session data\n",
      "10315\n",
      "10315\n",
      "customers with both deficit,disorder,task, customer and first session data\n",
      "10315\n",
      "10315\n"
     ]
    }
   ],
   "source": [
    "print('customers with disorders data')\n",
    "print(len(cust_disorders_reindexed['customer_id'].unique()))\n",
    "print(len(cust_disorders_reindexed))\n",
    "\n",
    "print('customers with deficits data')\n",
    "print(len(customer_deficits_reindexed['customer_id'].unique()))\n",
    "print(len(customer_deficits_reindexed))\n",
    "\n",
    "print('customers with both deficit and disorder data')\n",
    "print(len(deficits_disorders['customer_id'].unique()))\n",
    "print(len(deficits_disorders))\n",
    "\n",
    "print('customers with first session data for 2015 and 2016')\n",
    "print(len(first_session['user_id'].unique()))\n",
    "print(len(first_session))\n",
    "\n",
    "print('customers with both deficit,disorder, and first session data')\n",
    "print(len(first_session_deficits_disorders['user_id'].unique()))\n",
    "print(len(first_session_deficits_disorders))\n",
    "\n",
    "print('customers with both deficit,disorder,task and first session data')\n",
    "print(len(first_session_deficits_disorders_tasks['user_id'].unique()))\n",
    "print(len(first_session_deficits_disorders_tasks))\n",
    "\n",
    "print('customers with both deficit,disorder,task, customer and first session data')\n",
    "print(len(first_session_deficits_disorders_tasks_customers['customer_id'].unique()))\n",
    "print(len(first_session_deficits_disorders_tasks_customers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Save data <a class=\"anchor\" id=\"eighth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_session_deficits_disorders_tasks_customers.to_pickle(\"x_data/features.pkl\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:my_projects_env]",
   "language": "python",
   "name": "conda-env-my_projects_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
